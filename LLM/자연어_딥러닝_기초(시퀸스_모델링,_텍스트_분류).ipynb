{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewZ5CGMw2Ziy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 트랜스퍼 모델 : 2017\n",
        "  - 병렬처리\n",
        "  - 인코더, 디코더, 셀프 어텐션 아키텍처를 사용\n",
        "  - 셀프어텐션\n",
        "    - 입력데이터에 대한 쿼리(query), 키(key), 값(value) --> 스코어계산 -> 소프트 맥스 함수를 통해 정규화 각 단어의 가중치를 얻고, 이를사용해서 최종 출력\n",
        "  - 인코더 : 컨텍스트 (입력데이터를 처리해서 의미있는 표현), 여러층의 셀프어텐 , 뉴럴네트웍크로 성\n",
        "  - 디코더 : 인코더의 출력과 목표데이터를 입력으로 받아서 최종 출력\n",
        "\n",
        "  - seq2seq VS 트랜스포머\n",
        "    - RNN/GRU/LSTM 기반 VS 어텐션기반\n",
        "      - RNN 계열을이용해서 순차적용 / 어텐션매커니즘을 활용 순차처리없이 병렬처리, 긴 시퀀스 처리에 효율적\n",
        "    - 어텐션매커니즘\n",
        "      - seq2seq는 인코더와 디코더 사이에 어텐션을 추가한\n",
        "      - 트랜스포머 셀프어텐션을 사용해서 각 단어가 시퀀스 내의 다른 모든 단어와의 연관성을 스스로 이해\n",
        "      - 쿼리,키,벨류 벡터\n",
        "      - 문장 : 고양이가 방에서 뛰어다닌다\n",
        "      - 쿼리 : 고양이\n",
        "      - 키:  방에서       \n",
        "             뛰어다닌다\n",
        "      - 벡터 내적값을구한다  -- 유사도 기반\n",
        "      - 스코어 합이 1이 되도록 정규화-가중치(확률분포형태)\n",
        "\n",
        "    - 어텐션이 문장을 이해하는 과정\n",
        "      - 문장 : 고양이가 쥐를 쫓는다\n",
        "      - 고양이, 쥐, 쫓는다 각각의 쿼리,키, 값이 생\n",
        "      - 어텐션 스코어 : 고양이 쿼리벡터 쥐, 쫓는다 키 벡터를 비교 스코어를 계산 (ex 고양이하고 쫓는다 스코어가 높게)\n",
        "      - 정규화 : softmax\n",
        "      - 최종출력 : 고양이라는 입력에 대해서 출력은 관련성에따라서 쫒는다 벡터가 더큰 비중으로 가중합\n",
        "\n",
        "\n",
        "  - 디코더\n",
        "    - 순차적으로 처리 / 병렬로처리\n",
        "    - 단일어텐션 매커니즘 / 멀티해드 어텐션(전체문맥을 고려한 어텐션)\n",
        "    - 이전상태에 의존을크게 / 시간관련 정보도 포함\n",
        "  \n",
        "  - 셀프어텐션\n",
        "    - 입력시퀀스의 모든  토큰이 각각의 모든 토큰과 관계를 자체적으로 비교해서 각 토큰의 중요성을 할당\n",
        "  - 멀티해드 어텐션\n",
        "    - 헤드를 사용: 고유한 가중치 메트릭스를 사용,쿼리,키,값벡터포함\n",
        "    - 헤드사이의 어텐션 스코어계산\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5nwDQ6VU2jHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ryi-htI1FpGq",
        "outputId": "5fcb341e-11ae-4e64-e9a0-7b164d4b90a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.11.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.23.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2M60fUUX-OL3",
        "outputId": "a6298229-a2e5-4739-d5de-7843b920c1d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "file_id = '1cjc0l-hwP2JTKDqYVKmIZ4ppFuA4ooVo'\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "gdown.download(download_url, 'data.zip', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "AbEFStWf55T3",
        "outputId": "312e6b2a-5965-422b-c922-9de7df6e4b43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cjc0l-hwP2JTKDqYVKmIZ4ppFuA4ooVo\n",
            "To: /content/data.zip\n",
            "100%|██████████| 4.03k/4.03k [00:00<00:00, 12.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCUzICuqDwPd",
        "outputId": "ad7242f6-810c-4048-96ff-13ef55220b89"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: train_outputs.npy       \n",
            "  inflating: train_inputs.npy        \n",
            "  inflating: data_configs.json       \n",
            "  inflating: vocabulary.txt          \n",
            "  inflating: train_targets.npy       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 로드\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "index_inputs = np.load(open('train_inputs.npy', 'rb'))\n",
        "index_outputs = np.load(open('train_outputs.npy', 'rb'))\n",
        "index_targets = np.load(open('train_targets.npy', 'rb'))\n",
        "prepro_configs = json.load(open('data_configs.json', 'r'))"
      ],
      "metadata": {
        "id": "_RE0uxG1D1iC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = prepro_configs['char2idx']\n",
        "end_index = prepro_configs['end_symbol']\n",
        "model_name = 'transformer'\n",
        "vocab_size = prepro_configs['vocab_size']\n",
        "BATCH_SIZE = 2\n",
        "MAX_SEQUENCE = 25\n",
        "EPOCHS = 30\n",
        "VALID_SPLIT = 0.1\n",
        "\n",
        "kargs = {'model_name': model_name,\n",
        "         'num_layers': 2,\n",
        "         'd_model': 512,\n",
        "         'num_heads': 8,\n",
        "         'dff': 2048,\n",
        "         'input_vocab_size': vocab_size,\n",
        "         'target_vocab_size': vocab_size,\n",
        "         'maximum_position_encoding': MAX_SEQUENCE,\n",
        "         'end_token_idx': char2idx[end_index],\n",
        "         'rate': 0.1\n",
        "        }"
      ],
      "metadata": {
        "id": "LWDBFmmcEtb8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 포워드 마스킹  :시퀀스데이터 대해 패딩 마스크생성-> 패딩된 정보를 무시하고 중요한 정보에 주의를 기울\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32) # trhe, false -> 0.0 ,1.0\n",
        "    return seq[:,tf.newaxis, tf.newaxis,:]  # (batch_size,seq_len) -> (batch_size, 1,1,seq_len)\n",
        "    # Scaled dot-product Attention  스케일드 점수기반 어텐"
      ],
      "metadata": {
        "id": "0cHeGn2fE6m6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lower triangular Matrix  하삼각 행렬 : 대각선(좌상->우하)아래의 값은 0가 아니고 위쪽은 전부 0인\n",
        "# 임계치보다 크거나 같으면 아래쪽... .나머지는 모두 0\n",
        "# 트랜스포머 look ahead mask(미래를 내다보는 마스크) : 현재와 과거의 정보만 사용하도록\n",
        "# 각 토큰이 자신보다 이후에 있는 토큰을 참조하지 않도록 제한\n",
        "# 1 0 0 0 첫번재 토큰(자신만 본다)\n",
        "# 1 1 0 0 두번재 토큰은 첫번째와 두번재 토큰을 본다.\n",
        "# 1 1 1 0 세번째 토큰은 첫번재와 두번재 세번째 토큰을\n",
        "# 1 1 1 1\n"
      ],
      "metadata": {
        "id": "1IX_2EDWIvn7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번재 토큰은 현재를 제외한 나머지를 마스킹\n",
        "1- tf.linalg.band_part(tf.ones((5, 5)), -1, 0) # # 현재와 이전 토큰만 보도록 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNXooXqvKlV6",
        "outputId": "ca42fb20-e71e-4a75-f956-98b408abb4d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[0., 1., 1., 1., 1.],\n",
              "       [0., 0., 1., 1., 1.],\n",
              "       [0., 0., 0., 1., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어해드 마스크\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "# 패딩과 미래의 토큰 참조를 차단\n",
        "def create_masks(inp,tar):\n",
        "  '''\n",
        "  inp 인코더에 전달될 입력 시퀀스\n",
        "  tar 디코더에 전달될 타겟 시퀀스\n",
        "  '''\n",
        "  enc_padding_mask = create_padding_mask(inp) # 패딩토큰( 0 )을 마스킹\n",
        "  dec_padding_mask = create_padding_mask(inp) # 패딩토큰( 0 )을 마스킹\n",
        "  dec_target_padding_mask = create_padding_mask(tar) # 패딩토큰( 0 )을 마스킹\n",
        "\n",
        "  # 타겟의 길이만큼 하삼각형 행렬\n",
        "  # 첫번째 어텐션 블럭에서 미래의 토큰 참조 방지\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1]) # 미래\n",
        "  # 마스크 결합 : 두개중에 더 큰 값을 취함\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask) # 패딩과 미래\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ],
      "metadata": {
        "id": "jkzvXXOVGxcl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_padding_mask, look_ahead_mask, dec_padding_maks =  create_masks(index_inputs, index_outputs)"
      ],
      "metadata": {
        "id": "KND6TVmONZ9Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 포지셔널 인코딩 : 트랜스포머 모델에서 입력시퀀스의 위치 정보를 임베딩에 추가\n",
        "# RNN 계열을 사용하지 않아서 순환구조가 없기때문에 순서를 인식시킬수 있도록 위치정보가필요\n",
        "# 위치 정보를추가해서 각 단어의 상대적인 위치를 알 수 있게\n",
        "# 각도 비율 계산 : 각 차원에서 사용하는 주파수 값을 계산\n",
        "def get_angles(pos, i, d_model):\n",
        "  '''\n",
        "  pos : 시퀀스에서의 위치\n",
        "  i : 포지션의 차원 인덱스\n",
        "  d_model : 모델의 차원\n",
        "  '''\n",
        "  # i//2 짝 홀을 구분 -> 사인함수 코사인함수를 사용하기 위한 패턴\n",
        "  angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model)) # 주파수 기반의 스케일링\n",
        "  return pos * angle_rates # 위치 * 주파수비율\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  '''\n",
        "  position : 시퀀스의 길이\n",
        "  d_model : 임베딩 벡터의 차원\n",
        "  '''\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                        np.arange(d_model)[np.newaxis, :],\n",
        "                        d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  # 사인과 코사인을 주기적으로 사용는 이유 --> 성능향상\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...] # shape 모양을 맞춰줌\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32) # 텐서로 변환"
      ],
      "metadata": {
        "id": "-vTgGgPLSSz-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스에서 어떤 부분에 더 주의를 기울일지 결정\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "    # 넘파이 a.dot(b)  a@b   닷 프로덕트-->내적연산\n",
        "    # 각 쿼리가 모든 키와 얼마나 유사한지 측정, 어텐션 스코어\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "    # v(값) * 어텐션 가중치의 행렬곱 => 최종 어텐션 생성\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "rmOXgq7TTsgG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 트랜스포머 모델\n",
        "\n",
        "\n",
        "# 패딩(빈자리 매꾸기 0), 마스킹(의미없는 정보를 참조하지 않도록 참조하지 않는 위치를 얻기위해서 해당 값이 1)\n",
        "\n",
        "# 포지셔널 인코딩(순차처리를 위해서 위치정보. 인덱스 짝수면 싸인함수 홀수면 코사인함수 )\n",
        "\n",
        "# 어텐션 : 토큰에 가중치를 부여(중요한 단어에)\n",
        "  # 참고 : 셀프 어텐션 : 각 단어가 자신을 포함한 모든 단어와 관련있는지 학습해서 중요 정보 찾는게\n",
        "\n",
        "# 멀티 헤드 어텐션 : 하나의 어텐션만 사용할 경우 모델이 특정한 부분에 과도하게 집중을 방지\n",
        "  # 여러개의 어텐션 메커니즘을 병렬로 적용(어텐션 헤드를 사용해서 서로 다른 정보의 관계를 학습)\n",
        "  # 각 헤드가 독립적으로 다른 부분에 집중 :\n",
        "    # 하나의 헤드가 특정 단어간의 관계를 집중적으로 학습하고 있을때\n",
        "    # 다른 헤드는 또 다른 단어간의 관계를 학습\n",
        "    # ex ) 한 헤드 주어와 동사간의 관계, 또 다른 헤드는 형용사와 명사간의 관계 학습\n",
        "    # ex) The cat sat on the mat\n",
        "    # 첫번째 헤더 : The, cat\n",
        "    # 두번째 헤더 : cat, on\n",
        "    # 세번째 헤더 : 전체문장구조\n",
        "\n",
        "# 피드 포워드 네트웍(Feed Forwad Network)\n",
        "  # 어텐션 이후에 정보를 처리하는 레이어(완전연결레이어.) -- FC 학습.. 비선형구조로\n",
        "\n",
        "# 인코더 레이어: 어텐션 + 피드포워드 네트웍으로 구성\n",
        "\n",
        "# 디코더 레이어 : 인코더 레이어와 비슷  두가지 어텐션메커니즘사용\n",
        "  # 셀프어텐션 : 입력 시퀀스간의 관계를 학습\n",
        "  # 인코더 출력과 디코더의 입력간의 관계를 학습-> 마스킹을 이용해서 미래시점의 정보 참조 방지\n",
        "\n",
        "# 인코더 : 인코더 레이어 여러개를 사용(연결)\n",
        "# 디코더 : 출력 예측 , 디코더 레이어 연결\n",
        "\n",
        "# 트랜스포머 모델 : 인코더와 디코더를 연결\n",
        "\n",
        "# 로스함수, accuracy함수 : 교차엔트로피 로스 함수\n",
        "\n",
        "# 학습 : 컴파일, 콜벡.. 학습\n",
        "# 평가 : 평가\n",
        "# 예측 : 답변"
      ],
      "metadata": {
        "id": "44Er0q6uZFzI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(x,y):\n",
        "  assert y > 0\n",
        "  print(x / y)\n",
        "\n",
        "test(5,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "yLbGm1RhjsxM",
        "outputId": "aa2eeade-6412-4608-e5cb-9506ccf6c7c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a83ff4f50323>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-a83ff4f50323>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = kargs['num_heads']  # 헤더수\n",
        "        self.d_model = kargs['d_model'] # 전체 입력벡터의 크기\n",
        "\n",
        "        # 일관성유지를 위해 동일한 차원수를 가지도록\n",
        "        assert self.d_model % self.num_heads == 0\n",
        "        # 각 헤드에 배분할수 있는 차원 수\n",
        "        self.depth = self.d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
        "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
        "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(kargs['d_model'])  # 모든 헤더의 출력을 결합\n",
        "\n",
        "    # 입력텐서를 여러개의 헤드로 나눔 각 헤드가 독립적으로 계산-> 핵심\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3]) # batch_size, num_head, seq_len, depth\n",
        "\n",
        "    def __call__(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask) # 입력의 중요한 부분에 집중\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "def point_wise_feed_forward_network(**kargs):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
        "    ])\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(**kargs)\n",
        "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(**kargs) # 셀프어텐션을 위함\n",
        "        self.mha2 = MultiHeadAttention(**kargs) # 인코더-디코더용\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(**kargs) # 어텐션 결과에 비선형을 적용 표현력을 높임\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "\n",
        "    def __call__(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = kargs['d_model']\n",
        "        self.num_layers = kargs['num_layers']\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
        "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'],\n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(**kargs)\n",
        "                           for _ in range(self.num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = kargs['d_model']\n",
        "        self.num_layers = kargs['num_layers']\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n",
        "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(**kargs)\n",
        "                           for _ in range(self.num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # 스케일링 기울기가 너무크거가 작아지는것을 방지 모델안정적으로\n",
        "        x += self.pos_encoding[:, :seq_len, :] # 순서정보 유\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "id": "6yTfsdbpacNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 트랜스포머 모델\n",
        "STD_INDEX = 1\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, **kargs):\n",
        "      super(Transformer, self).__init__()\n",
        "\n",
        "      self.end_token_idx = kargs['end_token_idx']\n",
        "\n",
        "      self.encoder = Encoder(**kargs)\n",
        "      self.decoder = Decoder(**kargs)\n",
        "\n",
        "      self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
        "\n",
        "  def __call__(self, x):\n",
        "      inp, tar = x\n",
        "\n",
        "      enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
        "      enc_output = self.encoder(inp, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "      # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "      dec_output, _ = self.decoder(\n",
        "          tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "      final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "      return final_output\n",
        "\n",
        "  def inference(self, x):\n",
        "      inp = x\n",
        "      tar = tf.expand_dims([STD_INDEX], 0)\n",
        "\n",
        "      enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
        "      enc_output = self.encoder(inp, enc_padding_mask)\n",
        "\n",
        "      predict_tokens = list()\n",
        "      for t in range(0, MAX_SEQUENCE):\n",
        "          dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "          final_output = self.final_layer(dec_output)\n",
        "          outputs = tf.argmax(final_output, -1).numpy()\n",
        "          pred_token = outputs[0][-1]\n",
        "          if pred_token == self.end_token_idx:\n",
        "              break\n",
        "          predict_tokens.append(pred_token)\n",
        "          tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
        "          _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
        "\n",
        "      return predict_tokens"
      ],
      "metadata": {
        "id": "2HsTV3pCo6CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델"
      ],
      "metadata": {
        "id": "6fqz3ybx7opp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "def loss(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "    pred *= mask\n",
        "    acc = train_accuracy(real, pred)\n",
        "\n",
        "    return tf.reduce_mean(acc)\n",
        ""
      ],
      "metadata": {
        "id": "GvOteINn7qXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(**kargs)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=loss,\n",
        "              metrics=[accuracy])"
      ],
      "metadata": {
        "id": "8wcdjgmp7xCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 콜벡\n",
        "# overfitting을 막기 위한 ealrystop 추가\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
        "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
        "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
        "\n",
        "checkpoint_path = model_name + '.weights.h5'\n",
        "checkpoint_dir = './'\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "metadata": {
        "id": "RFWr7glM78ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "history = model.fit([index_inputs,index_outputs], index_targets, batch_size = BATCH_SIZE,epochs=EPOCHS,\n",
        "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
      ],
      "metadata": {
        "id": "9cgxBYXP8Yxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5oFNuFi-Y5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}