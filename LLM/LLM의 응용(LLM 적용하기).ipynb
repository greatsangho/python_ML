{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.54.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.0-cp312-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "     ---------------------------------------- 0.0/149.4 kB ? eta -:--:--\n",
      "     ---------------------------- --------- 112.6/149.4 kB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 149.4/149.4 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\miniconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\miniconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\miniconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.54.0-py3-none-any.whl (389 kB)\n",
      "   ---------------------------------------- 0.0/389.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 389.3/389.3 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.0/78.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading jiter-0.7.0-cp312-none-win_amd64.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.9 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 61.4/199.9 kB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 184.3/199.9 kB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.9/199.9 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.9 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 163.8/434.9 kB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 327.7/434.9 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.9/434.9 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.23.4-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/1.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: pydantic-core, jiter, h11, annotated-types, pydantic, httpcore, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.7.0 openai-1.54.0 pydantic-2.9.2 pydantic-core-2.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x22dfa88b8c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# openai.api_key = \"\"\n",
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",  # 무료\n",
    "    # model = \"gpt-4o\",  # 유로\n",
    "    messages = [\n",
    "        {'role':'system','content':'You ar a helpful assistant'},\n",
    "        {'role':'user','content':'여기 지하에 구내식당 어때?'},\n",
    "        {'role':'assistant','content':'가성비가 좋아서 많이들 이용하는 곳이에요.. 적극 추천합니다.'},\n",
    "        {'role':'user','content':'오늘점심은 어디서 먹을까?'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘 점심은 기분전환도 할 겸 새로운 곳을 시도해보는 건 어때요? 주변에 최근에 생긴 레스토랑이나 카페가 있다면 가보는 것도 좋을 것 같습니다. 평소에 먹지 않던 메뉴를 선택해보는 것도 흥미로울 것 같네요. 다른 추천을 원하시면 주변 지역이나 선호하는 음식 스타일을 알려주세요!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <openai.OpenAI at 0x22dfa88b8c0>\n",
    "# 'The 2020 World Series was played at Globe Life Field in Arlington, Texas. Due to the COVID-19 pandemic, Major League Baseball decided to use a neutral site for the World Series that year, and all the games were held there.'\n",
    "\n",
    "# 'The 2020 World Series was played at a neutral site due to the COVID-19 pandemic. The games were held at Globe Life Field in Arlington, Texas.'\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.0.68:5001\n",
      "Press CTRL+C to quit\n",
      "192.168.0.68 - - [05/Nov/2024 09:42:38] \"GET /prompt HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# flask를 이용해서 \n",
    "import openai\n",
    "from flask import Flask, jsonify, request\n",
    "import os\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/prompt', methods = ['POST'])\n",
    "def generate_answer():    \n",
    "    if request.method == 'POST':\n",
    "        prompt = request.json['prompt']\n",
    "        openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "        pre_prompt = '한국어로 대답해줘\\n\\n'\n",
    "        response = openai.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo\",  # 무료\n",
    "            # model = \"gpt-4o\",  # 유로\n",
    "            messages = [\n",
    "                {'role':'system','content':'You ar a helpful assistant'},\n",
    "                {'role':'user','content':pre_prompt + prompt},                \n",
    "            ],\n",
    "            max_tokens = 3000,\n",
    "            stop = None,\n",
    "            temperature = 0.5  # 출력의 다양성  0.2 매우 보수적이고 일관성을유지: 간결한 답변,  0.8: 매우 창의적인 답변\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        return jsonify({'answer' : answer})\n",
    "\n",
    "app.run(host=\"0.0.0.0\", debug=False, port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
