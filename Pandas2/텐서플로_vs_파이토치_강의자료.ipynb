{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcW9Bf5cvFpn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 딥러닝\n",
        "  - 지도학습\n",
        "    - 예측\n",
        "    - 분류\n",
        "  - 비지도학습\n",
        "    - 차원축소\n",
        "    - 오토인코더\n",
        "    - 군집"
      ],
      "metadata": {
        "id": "ZFQI4D8DvNNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 텐서플로 : 예측\n"
      ],
      "metadata": {
        "id": "wBJJ9-35vcq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TLseuo_dvYM2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "(x,y),(x_test, y_test) = tf.keras.datasets.california_housing.load_data()\n",
        "x_train,x_val,y_train,y_val =  train_test_split(x,y,random_state=123)"
      ],
      "metadata": {
        "id": "PABW8BbRwKLV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0YKAiy8wAEx",
        "outputId": "7a853e6c-a217-43c9-c04a-a9f79e5b9150"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12384, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_val = scaler.transform(x_val)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "FDmyuJXFxOwV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]),\n",
        "    tf.keras.layers.Dense(15,activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss='mse',optimizer='adam')\n",
        "hist = model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=20, batch_size=32)\n",
        "test_loss = model.evaluate(x_test,y_test)\n",
        "print(f\"test loss : {test_loss}\")\n",
        "from sklearn.metrics import r2_score\n",
        "y_pred = model.predict(x_test)\n",
        "r2score = r2_score(y_test,y_pred)\n",
        "print(f\"r2score : {r2score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GDKg-1rfwT-O",
        "outputId": "9274bf86-f920-4970-d984-afccf0950df5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 208425.5625 - val_loss: 204515.4219\n",
            "Epoch 2/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 206026.2656 - val_loss: 203089.2031\n",
            "Epoch 3/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 205982.0625 - val_loss: 199415.5312\n",
            "Epoch 4/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 200745.2344 - val_loss: 192877.8906\n",
            "Epoch 5/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 192080.0781 - val_loss: 183103.3281\n",
            "Epoch 6/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 184932.8438 - val_loss: 170165.8125\n",
            "Epoch 7/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 170406.2500 - val_loss: 155532.9219\n",
            "Epoch 8/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153196.6562 - val_loss: 141495.4375\n",
            "Epoch 9/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140589.0469 - val_loss: 128975.4062\n",
            "Epoch 10/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129192.7656 - val_loss: 118493.5781\n",
            "Epoch 11/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118187.5547 - val_loss: 109821.8047\n",
            "Epoch 12/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107599.4141 - val_loss: 103274.1953\n",
            "Epoch 13/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103456.1484 - val_loss: 98424.9297\n",
            "Epoch 14/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 99172.2188 - val_loss: 94611.2656\n",
            "Epoch 15/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 92990.2891 - val_loss: 91334.1562\n",
            "Epoch 16/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90334.6719 - val_loss: 88341.6172\n",
            "Epoch 17/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87602.6953 - val_loss: 85476.3281\n",
            "Epoch 18/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 83924.0859 - val_loss: 82704.9922\n",
            "Epoch 19/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81746.6250 - val_loss: 80076.8438\n",
            "Epoch 20/20\n",
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 77650.6562 - val_loss: 77558.6875\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77244.7188\n",
            "test loss : 75746.6796875\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "r2score : 0.19142472743988037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 머신러닝 RendomForest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor()\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)\n",
        "y_pred = model.predict(x_test)\n",
        "r2score = r2_score(y_test,y_pred)\n",
        "print(f\"r2score : {r2score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQDBisEYzJWr",
        "outputId": "1925cd59-b040-4982-c440-97a408e89178"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2score : 0.8003450750153709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치 -- 덴서구조의 자료구조\n",
        "# gpu(cuda) cpu 셋팅\n",
        "# 클래스형태\n",
        "# 데이터셋과 데이터로더( 배치크기만큼 ) --> 상속 클래스\n",
        " # getitem, len\n",
        "# 모델 : 상속을 받아서 클래스\n",
        " # forward : 전방계산, init에서 정의한 각 레이어를 결합\n",
        "\n",
        "# 학습루프 for\n",
        " # for  -- epoch\n",
        "   # for -- batch\n",
        "     # 옵티마이져 초기화(기울기)\n",
        "     # 모델에 학습용데이터 넣어서 예측값\n",
        "     # 손실함수를 정의해서 손실값을 구하고\n",
        "     # 손실값을 backward (기울기 계산)\n",
        "     # 옵티마이져를 통해서 기울기를 적용/업데이트\n",
        ""
      ],
      "metadata": {
        "id": "MNQJ3JYny8rm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape,y_train.shape\n",
        "torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M71TrJVx1jpP",
        "outputId": "63735e78-8c6e-42ce-cb19-ce3568787b4a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12384, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class DatasetCalifornia(torch.utils.data.Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.tensor(x, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.x[idx], self.y[idx]\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataset = DatasetCalifornia(x_train, y_train)\n",
        "val_dataset = DatasetCalifornia(x_val, y_val)\n",
        "test_dataset = DatasetCalifornia(x_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 모델생성\n",
        "class CaliforniaModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CaliforniaModel,self).__init__()\n",
        "    self.fc1 = nn.Linear(x_train.shape[1],30)\n",
        "    self.fc2 = nn.Linear(30,15)\n",
        "    self.fc3 = nn.Linear(15,1)\n",
        "  def forward(self,x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "model = CaliforniaModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # 옵티마이져\n",
        "loss_fn = nn.MSELoss() # 손실함수\n",
        "# 학습루프\n",
        "from tqdm import tqdm\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "  iterator = tqdm(train_dataloader)\n",
        "  for x,y in iterator:\n",
        "    optimizer.zero_grad()  # 기울기 초기화\n",
        "    y_pred = model(x)  # 예측\n",
        "    loss = loss_fn(y_pred,y) # 손실값(텐서)\n",
        "    loss.backward() # 기울기 계산\n",
        "    optimizer.step() # 기울기 업데이트\n",
        "    iterator.set_description(f\"epoch : {epoch+1} loss : {loss.item()}\")\n",
        "# 모델을 저장\n",
        "torch.save(model.state_dict(),'california.pth')\n",
        "# 모델 불러오기\n",
        "model = CaliforniaModel()\n",
        "model.load_state_dict(torch.load('california.pth'))\n",
        "# 모델 평가\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "  for x,y in test_dataloader:\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    test_loss += loss.item()\n",
        "test_loss /= len(test_dataloader)\n",
        "print(f\"test loss : {test_loss}\")\n",
        "from sklearn.metrics import r2_score\n",
        "y_pred = model(torch.tensor(x_test, dtype=torch.float32))\n",
        "r2score = r2_score(y_test,y_pred.detach().numpy() )\n",
        "print(f\"r2score : {r2score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A86NCDID2zqu",
        "outputId": "ed9d23e9-0b69-47bb-ed68-75bf6bc74a07"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch : 1 loss : 39831539712.0: 100%|██████████| 387/387 [00:02<00:00, 137.74it/s]\n",
            "epoch : 2 loss : 59469160448.0: 100%|██████████| 387/387 [00:02<00:00, 147.16it/s]\n",
            "epoch : 3 loss : 57475633152.0: 100%|██████████| 387/387 [00:03<00:00, 116.54it/s]\n",
            "epoch : 4 loss : 57024716800.0: 100%|██████████| 387/387 [00:03<00:00, 122.46it/s]\n",
            "epoch : 5 loss : 48321130496.0: 100%|██████████| 387/387 [00:02<00:00, 148.30it/s]\n",
            "epoch : 6 loss : 50781577216.0: 100%|██████████| 387/387 [00:02<00:00, 144.29it/s]\n",
            "epoch : 7 loss : 24944957440.0: 100%|██████████| 387/387 [00:02<00:00, 153.85it/s]\n",
            "epoch : 8 loss : 28634603520.0: 100%|██████████| 387/387 [00:02<00:00, 137.32it/s]\n",
            "epoch : 9 loss : 27624704000.0: 100%|██████████| 387/387 [00:03<00:00, 120.74it/s]\n",
            "epoch : 10 loss : 26898577408.0: 100%|██████████| 387/387 [00:03<00:00, 126.96it/s]\n",
            "epoch : 11 loss : 21470640128.0: 100%|██████████| 387/387 [00:02<00:00, 133.70it/s]\n",
            "epoch : 12 loss : 12650518528.0: 100%|██████████| 387/387 [00:02<00:00, 143.32it/s]\n",
            "epoch : 13 loss : 11306050560.0: 100%|██████████| 387/387 [00:02<00:00, 146.92it/s]\n",
            "epoch : 14 loss : 7200175104.0: 100%|██████████| 387/387 [00:03<00:00, 124.75it/s]\n",
            "epoch : 15 loss : 13088928768.0: 100%|██████████| 387/387 [00:03<00:00, 121.84it/s]\n",
            "epoch : 16 loss : 12981491712.0: 100%|██████████| 387/387 [00:02<00:00, 142.38it/s]\n",
            "epoch : 17 loss : 10776352768.0: 100%|██████████| 387/387 [00:02<00:00, 136.60it/s]\n",
            "epoch : 18 loss : 13322592256.0: 100%|██████████| 387/387 [00:02<00:00, 141.18it/s]\n",
            "epoch : 19 loss : 7386971648.0: 100%|██████████| 387/387 [00:02<00:00, 141.70it/s]\n",
            "epoch : 20 loss : 12378242048.0: 100%|██████████| 387/387 [00:02<00:00, 147.64it/s]\n",
            "<ipython-input-34-f1f92cb7b67f>:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('california.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss : 9929519530.666666\n",
            "r2score : 0.2531021237373352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 분류\n",
        "  - 텐서플로\n",
        "  - 파이토치"
      ],
      "metadata": {
        "id": "Lzkly0N7CxJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fashionmnist 분류\n",
        "(x,y),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ODthyHC0-F",
        "outputId": "47ac711f-7a68-4f4d-edca-2f98067ce383"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로\n",
        "x = x / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "SNeRcOnVC8z3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(x,y,stratify=y,random_state=45)"
      ],
      "metadata": {
        "id": "0-kJDW2FDtwp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9NzrzbvEHQB",
        "outputId": "c913699d-1fe4-4375-9cbc-03d1f1ee75e5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c-p-c-p-c-flatten-fc1-fc1\n",
        "tensorflow_model = tf.keras.Sequential([\n",
        "    # 입력 레이어\n",
        "    tf.keras.layers.Input(shape=x_train.shape[1:]),\n",
        "    # 채널정보 추가\n",
        "    tf.keras.layers.Reshape(target_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "tensorflow_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "hist = tensorflow_model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=10,batch_size=32)\n",
        "test_loss, test_acc = tensorflow_model.evaluate(x_test,y_test)\n",
        "print(f\"test loss : {test_loss}\")\n",
        "print(f\"test acc : {test_acc}\")\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "y_pred = tensorflow_model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred,axis=1)  # 10개 클래스에 대한 각각의 확률값의 최고값에 해당하는 인덱스가 곧 클래스번호\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IVy2QXY1D3Ch",
        "outputId": "6967d6ca-23d3-4ed6-ca37-4d523e878ea7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 43ms/step - accuracy: 0.7347 - loss: 0.7171 - val_accuracy: 0.8671 - val_loss: 0.3695\n",
            "Epoch 2/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 41ms/step - accuracy: 0.8723 - loss: 0.3439 - val_accuracy: 0.8904 - val_loss: 0.3036\n",
            "Epoch 3/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 41ms/step - accuracy: 0.8952 - loss: 0.2791 - val_accuracy: 0.8897 - val_loss: 0.2995\n",
            "Epoch 4/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 42ms/step - accuracy: 0.9097 - loss: 0.2408 - val_accuracy: 0.9032 - val_loss: 0.2680\n",
            "Epoch 5/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 40ms/step - accuracy: 0.9182 - loss: 0.2194 - val_accuracy: 0.9081 - val_loss: 0.2537\n",
            "Epoch 6/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 41ms/step - accuracy: 0.9308 - loss: 0.1883 - val_accuracy: 0.9060 - val_loss: 0.2655\n",
            "Epoch 7/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 42ms/step - accuracy: 0.9388 - loss: 0.1635 - val_accuracy: 0.9036 - val_loss: 0.2671\n",
            "Epoch 8/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 40ms/step - accuracy: 0.9468 - loss: 0.1422 - val_accuracy: 0.9094 - val_loss: 0.2655\n",
            "Epoch 9/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 40ms/step - accuracy: 0.9511 - loss: 0.1282 - val_accuracy: 0.9121 - val_loss: 0.2636\n",
            "Epoch 10/10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 42ms/step - accuracy: 0.9578 - loss: 0.1116 - val_accuracy: 0.9109 - val_loss: 0.2865\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9080 - loss: 0.3223\n",
            "test loss : 0.3012983798980713\n",
            "test acc : 0.9086999893188477\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.84      0.89      0.86      1000\n",
            "           3       0.93      0.91      0.92      1000\n",
            "           4       0.85      0.86      0.85      1000\n",
            "           5       0.98      0.98      0.98      1000\n",
            "           6       0.75      0.74      0.75      1000\n",
            "           7       0.94      0.96      0.95      1000\n",
            "           8       0.97      0.97      0.97      1000\n",
            "           9       0.97      0.95      0.96      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn9kNUF9Mgn5",
        "outputId": "7788416b-c6ca-4711-b8b6-c375b3aa6e6f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# fashionmnist 분류\n",
        "(x,y),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "# 텐서플로\n",
        "x = x / 255.0\n",
        "x_test = x_test / 255.0\n",
        "x_train,x_val,y_train,y_val = train_test_split(x,y,stratify=y,random_state=45)\n",
        "\n",
        "class FashionMnistDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.tensor(x, dtype=torch.float32)\n",
        "    self.x = self.x.unsqueeze(1)  #origin (none, 28 28) (none,1,28,28)\n",
        "    self.y = torch.tensor(y, dtype=torch.long)\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.x[idx], self.y[idx]\n",
        "# 데이터 로더\n",
        "train_dataset = FashionMnistDataset(x_train, y_train)\n",
        "val_dataset = FashionMnistDataset(x_val, y_val)\n",
        "test_dataset = FashionMnistDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 모델 정의\n",
        "# c-p-c-p-c-flattern-fc-fc\n",
        "class FashionMnist(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FashionMnist,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1)  # same padding\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2) # 14 14\n",
        "    self.conv2 = nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)  # same padding\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2) # 7 7\n",
        "    self.conv3 = nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1)  # same padding\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(128*7*7,128)\n",
        "    self.fc2 = nn.Linear(128,10)\n",
        "  def forward(self,x):\n",
        "    x = torch.relu( self.conv1(x) )\n",
        "    x = self.pool1(x)\n",
        "    x = torch.relu( self.conv2(x) )\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.flatten(x)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = FashionMnist().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # 옵티마이져\n",
        "loss_fn = nn.CrossEntropyLoss() # 손실함수\n",
        "# 학습루프\n",
        "# 파이토치의 conv 는 (batchsize,channel,....)\n",
        "for epoch in range(10):\n",
        "  iterator = tqdm(train_loader)\n",
        "  for x,y in iterator:\n",
        "    x = x.to(device)\n",
        "    y= y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    iterator.set_description(f\"epoch : {epoch+1} loss : {loss.item()}\")\n",
        "\n",
        "# 모델을 저장\n",
        "torch.save(model.state_dict(),'fashionmnist.pth')\n",
        "# 모델 불러오기\n",
        "model = FashionMnist()\n",
        "model.load_state_dict(torch.load('fashionmnist.pth'))\n",
        "# 모델 평가\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "  for x,y in test_loader:\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"test loss : {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "collapsed": true,
        "id": "5zRBATM8KMxB",
        "outputId": "7ce1eb99-0c32-4f6d-cf10-ed13e25bb800"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch : 1 loss : 0.7877084612846375: 100%|██████████| 1407/1407 [00:11<00:00, 122.78it/s]\n",
            "epoch : 2 loss : 0.6516703367233276: 100%|██████████| 1407/1407 [00:10<00:00, 133.87it/s]\n",
            "epoch : 3 loss : 0.03455927595496178: 100%|██████████| 1407/1407 [00:09<00:00, 149.83it/s]\n",
            "epoch : 4 loss : 0.009604541584849358: 100%|██████████| 1407/1407 [00:09<00:00, 145.48it/s]\n",
            "epoch : 5 loss : 0.07353999465703964: 100%|██████████| 1407/1407 [00:11<00:00, 118.04it/s]\n",
            "epoch : 6 loss : 0.1472821980714798: 100%|██████████| 1407/1407 [00:09<00:00, 155.15it/s]\n",
            "epoch : 7 loss : 0.04206119105219841: 100%|██████████| 1407/1407 [00:10<00:00, 136.44it/s]\n",
            "epoch : 8 loss : 0.09163087606430054: 100%|██████████| 1407/1407 [00:11<00:00, 122.22it/s]\n",
            "epoch : 9 loss : 0.4021851420402527: 100%|██████████| 1407/1407 [00:09<00:00, 150.94it/s]\n",
            "epoch : 10 loss : 0.09142746031284332: 100%|██████████| 1407/1407 [00:09<00:00, 154.48it/s]\n",
            "<ipython-input-1-4c109035e69d>:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('fashionmnist.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss : 0.33780995050903423\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 10000, 28, 28] to have 1 channels, but got 10000 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4c109035e69d>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4c109035e69d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 10000, 28, 28] to have 1 channels, but got 10000 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "data,target = next(iter(test_loader))\n",
        "pred = model(data)  # (32,10)\n",
        "pred = np.argmax(pred.detach().numpy(),axis=1)\n",
        "# y_pred = np.argmax(y_pred,axis=1)\n",
        "print(classification_report(target, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0tsLI7_T56-",
        "outputId": "14beabcd-fb6e-4c5c-af52-e646a02fc6a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       0.67      1.00      0.80         4\n",
            "           3       0.50      1.00      0.67         1\n",
            "           4       0.80      0.67      0.73         6\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      0.67      0.80         3\n",
            "           9       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.84        32\n",
            "   macro avg       0.85      0.83      0.82        32\n",
            "weighted avg       0.87      0.84      0.84        32\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yyPKY--vUxli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}