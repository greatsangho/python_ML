{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- GAN\n",
        "  - 생성자(Generator)\n",
        "  - 판별자(Discrimnator)\n",
        "  - 둘이 서로 경쟁하면서 학습"
      ],
      "metadata": {
        "id": "Z6xz244m4-iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "(x,y),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x = x.astype('float32')/255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_train,x_val,y_train,y_val = train_test_split(x,y, stratify=y, test_size=0.2)\n",
        "x_train.shape, x_val.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bc0Qfi0YBUlD",
        "outputId": "4f0ae56b-9675-4f84-f554-de6ae4f5f752"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28), (12000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = images.squeeze(axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "TBEWFCCyKcxT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fashion mnist\n",
        "import tensorflow as tf\n",
        "coding_size = 30  # 생성자에 입력되는 랜덤한 크기의 벡터 , 생성자가 처음 학습할때의 시작점\n",
        "Dense = tf.keras.layers.Dense  # 여러번 반복되므로...\n",
        "# 생성자\n",
        "generator = tf.keras.Sequential([\n",
        "  Dense(100, activation='relu',kernel_initializer='he_normal'),  # he_normal 안정적인 학습\n",
        "  Dense(150, activation='relu',kernel_initializer='he_normal'),\n",
        "  Dense(28*28, activation='sigmoid'),\n",
        "  tf.keras.layers.Reshape([28,28])\n",
        "])\n",
        "# 판별자\n",
        "discriminator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    Dense(150, activation='relu',kernel_initializer='he_normal'),\n",
        "    Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "gan = tf.keras.Sequential([generator, discriminator])  # 두 네트웍을 결합\n",
        "# GAN Adam 이나 rmsprop\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop') # 진짜인지 가짜인지 구분하는 판별자\n",
        "discriminator.trainable = False  # 가중치를 고정하는 역활  GAN에서 생성자만 학습되도록\n",
        "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "# 배치크기  - 너무 작으면 빠르고 학습이 불안정 , 너무크면 학습이 느려질수 있지만 안정적인 학습\n",
        "batch_size = 32  # 64 128\n",
        "# 데이터셋\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)  # 데이터를 하나씩 넘겨줌   1000 버퍼사이트의 크기\n",
        "# 일부신경망 고정된 배치크기를 필요로 할때 유용한 방법\n",
        "dataset = dataset.batch(batch_size,drop_remainder=True)  # 배치크기를 유지하기위해서 남는 데이터는 사용 안한다\n",
        "dataset.prefetch(1) # 성능최적화를 위한 설정 모델 현재배치를 처리하는동안 다음배치를 미리 준비해서 처리속도 향상"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ1N_k9hBztx",
        "outputId": "30cbdb68-062a-49ec-cc75-1971b3f30fbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=TensorSpec(shape=(32, 28, 28), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(dataset))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7Ar8lqGUHUAQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 함수\n",
        "def train_gan(gan,dataset,batch_size,codding_size, n_epochs):\n",
        "  generator, discriminator = gan.layers\n",
        "  for epoch in range(n_epochs):\n",
        "    print(f'에포크 : {epoch+1}')\n",
        "    for x_batch in dataset:\n",
        "      # 판별자 훈련 - 랜덤벡터데이터 - 노이즈데이터\n",
        "      noise = tf.random.normal(shape=[batch_size,codding_size])\n",
        "      generated_images = generator(noise)  # 가짜이미지 생성\n",
        "      # 생성된 가짜 이미지와 실제 이미지를 하나로 합침\n",
        "      x_fake_and_real = tf.concat([generated_images,x_batch],axis=0)\n",
        "      # 정답 레이블\n",
        "      y1 = tf.constant([[0.]]*batch_size + [[1.]]*batch_size)\n",
        "      # 판별자 훈련\n",
        "      discriminator.train_on_batch(x_fake_and_real,y1)\n",
        "      # 생성자 훈련\n",
        "      noise = tf.random.normal(shape=[batch_size,codding_size])\n",
        "      y2 = tf.constant([[1.]]*batch_size)  # 생성자는 판별자를 속이는 목적이므로 판별자에게 1이라고 인시되도록 생성\n",
        "      gan.train_on_batch(noise,y2)  # gan 전체를 학습 - 판별자는 고정, 생성자만 학습\n",
        "    # 훈련과정에서 생성자 얼마나 진짜 같은 이미지를 생성하는지 시각화\n",
        "    plot_multiple_images(generated_images.numpy(), 8)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DUszifumHCn5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "train_gan(gan,dataset,batch_size, coding_size, n_epochs=10)"
      ],
      "metadata": {
        "id": "trAXb8ZzZFXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GAN - CNN 추가"
      ],
      "metadata": {
        "id": "kA_2j1EuUr5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "(x,y),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x = x.astype('float32')/255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_train,x_val,y_train,y_val = train_test_split(x,y, stratify=y, test_size=0.2)\n",
        "x_train.shape, x_val.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB-_NAPDU2p6",
        "outputId": "6128a4de-0da9-43da-d59e-39ad5442200a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28), (12000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자\n",
        "import tensorflow as tf\n",
        "coding_size = 100\n",
        "generator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(7*7*128, input_shape=[coding_size]),\n",
        "    tf.keras.layers.Reshape([7,7,128]),  # 공간을 작게 만들어서 많은 채널을 가지는 특징맵\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # 업셈플링 - 더 큰 크기의 이미지를 생성  strides=2 2배로키움  14 14 64\n",
        "    tf.keras.layers.Conv2DTranspose(64,kernel_size=5,strides=2,padding='same',activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # fashion mnist channel 1 흑백 28 28 1\n",
        "    # tanh 출력값을 -1 ~ 1 사이로 변경 GAN 이미지 픽셀을 -1 ~ 1 사이로  정규화 해서 사용할 예정\n",
        "    tf.keras.layers.Conv2DTranspose(1,kernel_size=5,strides=2,padding='same',activation='tanh'),\n",
        "])\n",
        "descriminator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,kernel_size=5,strides=2,padding='same',\n",
        "                           activation=tf.keras.layers.LeakyReLU(0.2)),  # 입력이 음수이면 작은 값 0.2곱해서 출력\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Conv2D(128,kernel_size=5,strides=2,padding='same',\n",
        "                           activation=tf.keras.layers.LeakyReLU(0.2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "gan = tf.keras.Sequential([generator,descriminator])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSNqHHO7UnF_",
        "outputId": "854a33f9-7eef-4a90-b03a-477a65dbeb2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "descriminator.trainable = False\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "3awqER9gXVc0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일링 및 크기변경\n",
        "# x_train 0 ~ 1  -1 ~ 1\n",
        "x_train_scaled = x_train.reshape(-1,28,28,1)*2-1  # -1 ~ 1"
      ],
      "metadata": {
        "id": "S21vxW5kX2Xj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "import matplotlib.pyplot as plt\n",
        "batch_size = 16\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x_train_scaled).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "train_gan(gan,dataset,batch_size,coding_size,n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ArpEHsrnYruz",
        "outputId": "16dd43ff-0db5-4b59-cb39-1759db7f4bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7a1c67e9a290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7a1c67d0eef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 작은데이터 mnist로 실행해 보기"
      ],
      "metadata": {
        "id": "bd-WDgjImgdN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "(x,y),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x = x.astype('float32')/255.0\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_train,x_val,y_train,y_val = train_test_split(x,y,stratify=y,test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XbcPDXdmuTT",
        "outputId": "4dc98265-4ecb-4159-ad14-e74f1cd4062b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 모델\n",
        "coding_size = 100\n",
        "generator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256,activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(28*28,activation='relu'),\n",
        "    tf.keras.layers.Reshape([28,28])\n",
        "])\n",
        "descriminator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(256,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid'),\n",
        "])\n",
        "# 판별자 모델 동결 (why? 단독으로만 학습되고.. gan으로 학습할때는 동결되어서 생성자위주로 학습)\n",
        "descriminator.compile(loss='binary_crossentropy',optimizer='adam')\n",
        "descriminator.trainable = False\n",
        "# gan 모델 정의 컴파일\n",
        "gan = tf.keras.Sequential([generator,descriminator])\n",
        "gan.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BD3N2_LrndsG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = images.squeeze(axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "iKvCEQO9pcX0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(gan,dataset,batch_size,codding_size, n_epochs):\n",
        "  generator, discriminator = gan.layers\n",
        "  for epoch in range(n_epochs):\n",
        "    print(f'에포크 : {epoch+1}')\n",
        "    for x_batch in dataset:\n",
        "      # 판별자 훈련 - 랜덤벡터데이터 - 노이즈데이터\n",
        "      noise = tf.random.normal(shape=[batch_size,codding_size])\n",
        "      generated_images = generator(noise)  # 가짜이미지 생성\n",
        "      # 생성된 가짜 이미지와 실제 이미지를 하나로 합침\n",
        "      x_fake_and_real = tf.concat([generated_images,x_batch],axis=0)\n",
        "      # 정답 레이블\n",
        "      y1 = tf.constant([[0.]]*batch_size + [[1.]]*batch_size)\n",
        "      # 판별자 훈련\n",
        "      discriminator.train_on_batch(x_fake_and_real,y1)\n",
        "      # 생성자 훈련\n",
        "      noise = tf.random.normal(shape=[batch_size,codding_size])\n",
        "      y2 = tf.constant([[1.]]*batch_size)  # 생성자는 판별자를 속이는 목적이므로 판별자에게 1이라고 인시되도록 생성\n",
        "      gan.train_on_batch(noise,y2)  # gan 전체를 학습 - 판별자는 고정, 생성자만 학습\n",
        "    # 훈련과정에서 생성자 얼마나 진짜 같은 이미지를 생성하는지 시각화\n",
        "    plot_multiple_images(generated_images.numpy(), 8)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1A5MvY7MpFpu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "train_gan(gan,dataset,batch_size,coding_size,n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_4jjZdipqnU",
        "outputId": "b1d30f10-2ed8-4752-ad41-1a3de49fa507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7e282424f760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7e282424e3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvNYj4a8ZW_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VV6kchZ84ZGr"
      }
    }
  ]
}