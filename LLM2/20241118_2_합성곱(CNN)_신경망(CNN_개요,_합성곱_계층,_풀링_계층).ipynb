{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76VlQtv3cR9r",
    "outputId": "8ec72824-30f7-4d47-eaa1-f24dfb856038"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8adhrVnabXDP",
    "outputId": "d8b7d955-5daa-4f9f-aabd-e1d1afc2b120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/sangho/.cache/kagglehub/datasets/fournierp/captcha-version-2-images/versions/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]/home/sangho/miniconda3/envs/ml2/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1133: UserWarning: The operator 'aten::_thnn_fused_gru_cell' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /__w/1/s/pytorch-directml-plugin/torch_directml/csrc/dml/dml_cpu_fallback.cpp:15.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "  0%|          | 0/104 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::_thnn_fused_gru_cell' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_thnn_fused_gru_cell' is only available for these backends: [CUDA, PrivateUse1, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44504 [kernel]\nPrivateUse1: registered at /__w/1/s/pytorch-directml-plugin/torch_directml/csrc/dml/dml_cpu_fallback.cpp:58 [backend fallback]\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:14745 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: registered at ../aten/src/ATen/autocast_mode.cpp:248 [kernel]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:202 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 206\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, label \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    205\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 206\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  CRNN의 출력값\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# CTC 손실 계산은 텐서의 모양까지 넣어줘야 함\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# 정수형으로 간단하게 preds와 label의 모양을 만들어주자\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# 시계열을 묶은 모양을 나타내는 변수\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     preds_size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mIntTensor([preds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 172\u001b[0m, in \u001b[0;36mCRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    169\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# GRU로 시계열 정보 추출\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# FC층으로 각 픽셀 분류\u001b[39;00m\n\u001b[1;32m    175\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml2/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml2/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml2/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1133\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1137\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_thnn_fused_gru_cell' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_thnn_fused_gru_cell' is only available for these backends: [CUDA, PrivateUse1, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44504 [kernel]\nPrivateUse1: registered at /__w/1/s/pytorch-directml-plugin/torch_directml/csrc/dml/dml_cpu_fallback.cpp:58 [backend fallback]\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:18859 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:14745 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: registered at ../aten/src/ATen/autocast_mode.cpp:248 [kernel]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:202 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"fournierp/captcha-version-2-images\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "from glob import glob\n",
    "imeages = glob('/home/sangho/.cache/kagglehub/datasets/fournierp/captcha-version-2-images/versions/2/**/*.png',recursive=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# 문자들로부터 BOW를 만드는 함수\n",
    "def get_BOW(corpus):\n",
    "   # 공백문자 <pad>를 0으로 설정\n",
    "   BOW = {\"<pad>\":0}\n",
    "\n",
    "   # corpus의 문자들을 이용해 BOW에 고유번호 추가\n",
    "   for letter in corpus:\n",
    "       if letter not in BOW.keys():\n",
    "           BOW[letter] = len(BOW.keys())\n",
    "\n",
    "   return BOW\n",
    "\n",
    "\n",
    "class Captcha(Dataset):\n",
    "   def __init__(self, pth, train=True):\n",
    "       # 소문자와 숫자만 정답으로 이용\n",
    "       self.corpus = string.ascii_lowercase + string.digits\n",
    "       self.BOW = get_BOW(self.corpus)\n",
    "\n",
    "       # 불러올 이미지 파일의 경로\n",
    "       self.imgfiles = glob.glob(pth+\"/*.png\")\n",
    "\n",
    "       self.train = train\n",
    "       self.trainset = self.imgfiles[:int(len(self.imgfiles)*0.8)]\n",
    "       self.testset = self.imgfiles[int(len(self.imgfiles)*0.8):]\n",
    "\n",
    "   # 문자와 숫자를 고유번호로 치환\n",
    "   def get_seq(self, line):\n",
    "       label = []\n",
    "\n",
    "       for letter in line:\n",
    "           label.append(self.BOW[letter])\n",
    "\n",
    "       return label\n",
    "\n",
    "   def __len__(self):\n",
    "       if self.train:\n",
    "           return len(self.trainset)\n",
    "       else:\n",
    "           return len(self.testset)\n",
    "\n",
    "   def __getitem__(self, i):\n",
    "       if self.train:\n",
    "           # png파일을 RGB파일로 변환\n",
    "           data = Image.open(self.trainset[i]).convert(\"RGB\")\n",
    "\n",
    "           label = self.trainset[i].split(\"/\")[-1]\n",
    "           # 파일이름에서 확장자를 제거\n",
    "           label = label.split(\".png\")[0]\n",
    "           # 정답 문자열을 BOW의 순열로 변환\n",
    "           label = self.get_seq(label)\n",
    "\n",
    "           data = np.array(data).astype(np.float32)\n",
    "           # 파이토치는 채널이 가장 앞에 와야 함\n",
    "           data = np.transpose(data, (2, 0, 1))\n",
    "           label = np.array(label)\n",
    "\n",
    "           return data, label\n",
    "\n",
    "       else:\n",
    "           data = Image.open(self.testset[i]).convert(\"RGB\")\n",
    "           label = self.testset[i].split(\"/\")[-1]\n",
    "           label = label.split(\".png\")[0]\n",
    "           label = self.get_seq(label)\n",
    "\n",
    "           data = np.array(data).astype(np.float32)\n",
    "           label = np.array(label)\n",
    "\n",
    "           return data, label\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 3X5 크기의 커널을 이용\n",
    "class BasicBlock(nn.Module):\n",
    "   def __init__(self,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(3, 5),\n",
    "                stride=(2, 1)):\n",
    "       super(BasicBlock, self).__init__()\n",
    "\n",
    "       self.c1 = nn.Conv2d(in_channels=in_channels,\n",
    "                           out_channels=out_channels,\n",
    "                           kernel_size=kernel_size,\n",
    "                           stride=stride)\n",
    "       self.c2 = nn.Conv2d(in_channels=out_channels,\n",
    "                           out_channels=out_channels,\n",
    "                           kernel_size=(3, 3), padding=1)\n",
    "\n",
    "       self.downsample = nn.Conv2d(in_channels=in_channels,\n",
    "                                   out_channels=out_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride)\n",
    "\n",
    "       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "       self.relu = nn.ReLU()\n",
    "\n",
    "   def forward(self, x):\n",
    "       x_ = x\n",
    "\n",
    "       x = self.c1(x)\n",
    "       x = self.bn1(x)\n",
    "       x = self.relu(x)\n",
    "       x = self.c2(x)\n",
    "       x = self.bn2(x)\n",
    "\n",
    "       x_ = self.downsample(x_)\n",
    "\n",
    "       x += x_\n",
    "       x = self.relu(x)\n",
    "\n",
    "       return x\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "   def __init__(self, output_size):\n",
    "       super(CRNN, self).__init__()\n",
    "\n",
    "       # CNN층의 정의\n",
    "       self.c1 = BasicBlock(in_channels=3, out_channels=64)\n",
    "       self.c2 = BasicBlock(in_channels=64, out_channels=64)\n",
    "       self.c3 = BasicBlock(in_channels=64, out_channels=64)\n",
    "       self.c4 = BasicBlock(in_channels=64, out_channels=64)\n",
    "       self.c5 = nn.Conv2d(64, 64, kernel_size=(2, 5))\n",
    "\n",
    "       # 텍스트 정보를 추출할 GRU층\n",
    "       self.gru = nn.GRU(64, 64, batch_first=False)\n",
    "\n",
    "       # 분류를 위한 MLP층\n",
    "       self.fc1 = nn.Linear(in_features=64, out_features=128)\n",
    "       self.fc2 = nn.Linear(in_features=128, out_features=output_size)\n",
    "       self.relu = nn.ReLU()\n",
    "\n",
    "   def forward(self, x):\n",
    "       # 입력텐서의 모양(B, 3, 50, 200)\n",
    "       x = self.c1(x)\n",
    "       x = self.c2(x)\n",
    "       x = self.c3(x)\n",
    "       x = self.c4(x)\n",
    "       x = self.c5(x)\n",
    "       # 특징 추출 후 텐서의 모양(B, 64, 1, 180)\n",
    "\n",
    "       # (B, 64, 180)으로 모양을 변경\n",
    "       x = x.view(x.shape[0], 64, -1)\n",
    "       # (B, 180, 64)로 모양을 변경\n",
    "       x = x.permute(2, 0, 1)\n",
    "\n",
    "       # GRU로 시계열 정보 추출\n",
    "       x, _ = self.gru(x)\n",
    "\n",
    "       # FC층으로 각 픽셀 분류\n",
    "       x = self.fc1(x)\n",
    "       x = self.relu(x)\n",
    "       x = self.fc2(x)\n",
    "\n",
    "       #CTC 손실 계산을 위해 로그 소프트맥스를 이용\n",
    "       x = F.log_softmax(x, dim=-1)\n",
    "\n",
    "       return x\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "import torch_directml\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch_directml.device()\n",
    "\n",
    "dataset = Captcha(\n",
    "    pth=\"/home/sangho/.cache/kagglehub/datasets/fournierp/captcha-version-2-images/versions/2/samples/\"\n",
    "    )\n",
    "loader = DataLoader(dataset, batch_size=8)\n",
    "\n",
    "model = CRNN(output_size=len(dataset.BOW)).to(device)\n",
    "\n",
    "optim = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(200):\n",
    "   iterator = tqdm.tqdm(loader)\n",
    "\n",
    "   # ❷ 정답에 사용할 label\n",
    "   for data, label in iterator:\n",
    "       optim.zero_grad()\n",
    "       preds = model(data.to(device))  #  CRNN의 출력값\n",
    "\n",
    "       # CTC 손실 계산은 텐서의 모양까지 넣어줘야 함\n",
    "       # 정수형으로 간단하게 preds와 label의 모양을 만들어주자\n",
    "\n",
    "       # 시계열을 묶은 모양을 나타내는 변수\n",
    "       preds_size = torch.IntTensor([preds.size(0)] * 8).to(device)\n",
    "       # 정답의 모양을 나타내는 변수\n",
    "       target_len = torch.IntTensor([len(txt) for txt in label]).to(device)\n",
    "\n",
    "       # 손실 계산\n",
    "       loss = nn.CTCLoss(blank=0)(\n",
    "           preds, label.to(device), preds_size, target_len)\n",
    "\n",
    "       loss.backward()   # 역전파\n",
    "       optim.step()\n",
    "\n",
    "       iterator.set_description(f\"epoch{epoch+1} loss:{loss.item()}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"//model/CRNN2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
